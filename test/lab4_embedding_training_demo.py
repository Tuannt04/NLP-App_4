from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from pathlib import Path

data_path = Path("data/UD_English-EWT/UD_English-EWT/en_ewt-ud-train.txt")
save_path = Path("results/word2vec_ewt.model")

# === Äá»c dá»¯ liá»‡u ===
print(f"ğŸ”¹ Äang Ä‘á»c dá»¯ liá»‡u tá»« {data_path}")
sentences = []
with open(data_path, "r", encoding="utf8") as f:
    for line in f:
        if line.strip():
            tokens = simple_preprocess(line)
            sentences.append(tokens)
print(f"âœ… ÄÃ£ Ä‘á»c {len(sentences)} cÃ¢u.")

# === Huáº¥n luyá»‡n Word2Vec (Skip-gram hoáº·c CBOW) ===
model = Word2Vec(
    sentences=sentences,
    vector_size=100,
    window=5,
    min_count=3,
    sg=1,          # sg=1 => Skip-gram, sg=0 => CBOW
    workers=4,
    epochs=10
)

# === LÆ°u mÃ´ hÃ¬nh ===
model.save(str(save_path))
print(f"ğŸ’¾ MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i: {save_path}")

# === Kiá»ƒm tra nhanh ===
print(model.wv.most_similar("language", topn=5))
